{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: opencv-python in /usr/local/lib/python3.11/dist-packages (4.12.0.88)\n",
      "Requirement already satisfied: tensorflow in /usr/local/lib/python3.11/dist-packages (2.20.0)\n",
      "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.11/dist-packages (1.7.1)\n",
      "Requirement already satisfied: pandas in /usr/local/lib/python3.11/dist-packages (2.3.1)\n",
      "Requirement already satisfied: matplotlib in /usr/local/lib/python3.11/dist-packages (3.10.5)\n",
      "Requirement already satisfied: tensorflow_datasets in /usr/local/lib/python3.11/dist-packages (4.9.9)\n",
      "Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (2.32.4)\n",
      "Requirement already satisfied: numpy<2.3.0,>=2 in /usr/local/lib/python3.11/dist-packages (from opencv-python) (2.1.2)\n",
      "Requirement already satisfied: absl-py>=1.0.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (2.3.1)\n",
      "Requirement already satisfied: astunparse>=1.6.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (1.6.3)\n",
      "Requirement already satisfied: flatbuffers>=24.3.25 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (25.2.10)\n",
      "Requirement already satisfied: gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (0.6.0)\n",
      "Requirement already satisfied: google_pasta>=0.1.1 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (0.2.0)\n",
      "Requirement already satisfied: libclang>=13.0.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (18.1.1)\n",
      "Requirement already satisfied: opt_einsum>=2.3.2 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (3.4.0)\n",
      "Requirement already satisfied: packaging in /usr/local/lib/python3.11/dist-packages (from tensorflow) (24.2)\n",
      "Requirement already satisfied: protobuf>=5.28.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (6.31.1)\n",
      "Requirement already satisfied: setuptools in /usr/local/lib/python3.11/dist-packages (from tensorflow) (77.0.1)\n",
      "Requirement already satisfied: six>=1.12.0 in /usr/lib/python3/dist-packages (from tensorflow) (1.16.0)\n",
      "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (3.1.0)\n",
      "Requirement already satisfied: typing_extensions>=3.6.6 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (4.12.2)\n",
      "Requirement already satisfied: wrapt>=1.11.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (1.17.3)\n",
      "Requirement already satisfied: grpcio<2.0,>=1.24.3 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (1.74.0)\n",
      "Requirement already satisfied: tensorboard~=2.20.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (2.20.0)\n",
      "Requirement already satisfied: keras>=3.10.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (3.11.2)\n",
      "Requirement already satisfied: h5py>=3.11.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (3.14.0)\n",
      "Requirement already satisfied: ml_dtypes<1.0.0,>=0.5.1 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (0.5.3)\n",
      "Requirement already satisfied: scipy>=1.8.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn) (1.16.1)\n",
      "Requirement already satisfied: joblib>=1.2.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn) (1.5.1)\n",
      "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn) (3.6.0)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas) (2025.2)\n",
      "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas) (2025.2)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (1.3.3)\n",
      "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (0.12.1)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (4.59.0)\n",
      "Requirement already satisfied: kiwisolver>=1.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (1.4.9)\n",
      "Requirement already satisfied: pillow>=8 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (11.0.0)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in /usr/lib/python3/dist-packages (from matplotlib) (2.4.7)\n",
      "Requirement already satisfied: array_record>=0.5.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow_datasets) (0.7.2)\n",
      "Requirement already satisfied: dm-tree in /usr/local/lib/python3.11/dist-packages (from tensorflow_datasets) (0.1.9)\n",
      "Requirement already satisfied: etils>=1.9.1 in /usr/local/lib/python3.11/dist-packages (from etils[edc,enp,epath,epy,etree]>=1.9.1; python_version >= \"3.11\"->tensorflow_datasets) (1.13.0)\n",
      "Requirement already satisfied: immutabledict in /usr/local/lib/python3.11/dist-packages (from tensorflow_datasets) (4.2.1)\n",
      "Requirement already satisfied: promise in /usr/local/lib/python3.11/dist-packages (from tensorflow_datasets) (2.3)\n",
      "Requirement already satisfied: psutil in /usr/local/lib/python3.11/dist-packages (from tensorflow_datasets) (7.0.0)\n",
      "Requirement already satisfied: pyarrow in /usr/local/lib/python3.11/dist-packages (from tensorflow_datasets) (21.0.0)\n",
      "Requirement already satisfied: simple_parsing in /usr/local/lib/python3.11/dist-packages (from tensorflow_datasets) (0.1.7)\n",
      "Requirement already satisfied: tensorflow-metadata in /usr/local/lib/python3.11/dist-packages (from tensorflow_datasets) (1.17.2)\n",
      "Requirement already satisfied: toml in /usr/local/lib/python3.11/dist-packages (from tensorflow_datasets) (0.10.2)\n",
      "Requirement already satisfied: tqdm in /usr/local/lib/python3.11/dist-packages (from tensorflow_datasets) (4.67.1)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests) (3.4.1)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests) (2.3.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests) (2025.1.31)\n",
      "Requirement already satisfied: wheel<1.0,>=0.23.0 in /usr/local/lib/python3.11/dist-packages (from astunparse>=1.6.0->tensorflow) (0.45.1)\n",
      "Requirement already satisfied: einops in /usr/local/lib/python3.11/dist-packages (from etils[edc,enp,epath,epy,etree]>=1.9.1; python_version >= \"3.11\"->tensorflow_datasets) (0.8.1)\n",
      "Requirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from etils[edc,enp,epath,epy,etree]>=1.9.1; python_version >= \"3.11\"->tensorflow_datasets) (2024.10.0)\n",
      "Requirement already satisfied: importlib_resources in /usr/local/lib/python3.11/dist-packages (from etils[edc,enp,epath,epy,etree]>=1.9.1; python_version >= \"3.11\"->tensorflow_datasets) (6.5.2)\n",
      "Requirement already satisfied: zipp in /usr/lib/python3/dist-packages (from etils[edc,enp,epath,epy,etree]>=1.9.1; python_version >= \"3.11\"->tensorflow_datasets) (1.0.0)\n",
      "Requirement already satisfied: rich in /usr/local/lib/python3.11/dist-packages (from keras>=3.10.0->tensorflow) (14.1.0)\n",
      "Requirement already satisfied: namex in /usr/local/lib/python3.11/dist-packages (from keras>=3.10.0->tensorflow) (0.1.0)\n",
      "Requirement already satisfied: optree in /usr/local/lib/python3.11/dist-packages (from keras>=3.10.0->tensorflow) (0.17.0)\n",
      "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.11/dist-packages (from tensorboard~=2.20.0->tensorflow) (3.8.2)\n",
      "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /usr/local/lib/python3.11/dist-packages (from tensorboard~=2.20.0->tensorflow) (0.7.2)\n",
      "Requirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from tensorboard~=2.20.0->tensorflow) (3.1.3)\n",
      "Requirement already satisfied: attrs>=18.2.0 in /usr/local/lib/python3.11/dist-packages (from dm-tree->tensorflow_datasets) (25.3.0)\n",
      "Requirement already satisfied: docstring-parser<1.0,>=0.15 in /usr/local/lib/python3.11/dist-packages (from simple_parsing->tensorflow_datasets) (0.17.0)\n",
      "Requirement already satisfied: googleapis-common-protos<2,>=1.56.4 in /usr/local/lib/python3.11/dist-packages (from tensorflow-metadata->tensorflow_datasets) (1.70.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.1.1 in /usr/local/lib/python3.11/dist-packages (from werkzeug>=1.0.1->tensorboard~=2.20.0->tensorflow) (2.1.5)\n",
      "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.11/dist-packages (from rich->keras>=3.10.0->tensorflow) (4.0.0)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.11/dist-packages (from rich->keras>=3.10.0->tensorflow) (2.19.1)\n",
      "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.11/dist-packages (from markdown-it-py>=2.2.0->rich->keras>=3.10.0->tensorflow) (0.1.2)\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager, possibly rendering your system unusable. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv. Use the --root-user-action option if you know what you are doing and want to suppress this warning.\u001b[0m\u001b[33m\n",
      "\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m25.0.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m25.2\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpython -m pip install --upgrade pip\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pip install -U opencv-python tensorflow scikit-learn pandas matplotlib tensorflow_datasets requests"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# IMPORTATION DES LIBRAIRIES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-08-14 09:35:22.202382: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "/usr/local/lib/python3.11/dist-packages/google/protobuf/runtime_version.py:98: UserWarning: Protobuf gencode version 5.28.3 is exactly one major version older than the runtime version 6.31.1 at tensorflow/core/framework/attr_value.proto. Please update the gencode to avoid compatibility violations in the next runtime release.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.11/dist-packages/google/protobuf/runtime_version.py:98: UserWarning: Protobuf gencode version 5.28.3 is exactly one major version older than the runtime version 6.31.1 at tensorflow/core/framework/tensor.proto. Please update the gencode to avoid compatibility violations in the next runtime release.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.11/dist-packages/google/protobuf/runtime_version.py:98: UserWarning: Protobuf gencode version 5.28.3 is exactly one major version older than the runtime version 6.31.1 at tensorflow/core/framework/resource_handle.proto. Please update the gencode to avoid compatibility violations in the next runtime release.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.11/dist-packages/google/protobuf/runtime_version.py:98: UserWarning: Protobuf gencode version 5.28.3 is exactly one major version older than the runtime version 6.31.1 at tensorflow/core/framework/tensor_shape.proto. Please update the gencode to avoid compatibility violations in the next runtime release.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.11/dist-packages/google/protobuf/runtime_version.py:98: UserWarning: Protobuf gencode version 5.28.3 is exactly one major version older than the runtime version 6.31.1 at tensorflow/core/framework/types.proto. Please update the gencode to avoid compatibility violations in the next runtime release.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.11/dist-packages/google/protobuf/runtime_version.py:98: UserWarning: Protobuf gencode version 5.28.3 is exactly one major version older than the runtime version 6.31.1 at tensorflow/core/framework/full_type.proto. Please update the gencode to avoid compatibility violations in the next runtime release.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.11/dist-packages/google/protobuf/runtime_version.py:98: UserWarning: Protobuf gencode version 5.28.3 is exactly one major version older than the runtime version 6.31.1 at tensorflow/core/framework/function.proto. Please update the gencode to avoid compatibility violations in the next runtime release.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.11/dist-packages/google/protobuf/runtime_version.py:98: UserWarning: Protobuf gencode version 5.28.3 is exactly one major version older than the runtime version 6.31.1 at tensorflow/core/framework/node_def.proto. Please update the gencode to avoid compatibility violations in the next runtime release.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.11/dist-packages/google/protobuf/runtime_version.py:98: UserWarning: Protobuf gencode version 5.28.3 is exactly one major version older than the runtime version 6.31.1 at tensorflow/core/framework/op_def.proto. Please update the gencode to avoid compatibility violations in the next runtime release.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.11/dist-packages/google/protobuf/runtime_version.py:98: UserWarning: Protobuf gencode version 5.28.3 is exactly one major version older than the runtime version 6.31.1 at tensorflow/core/framework/graph.proto. Please update the gencode to avoid compatibility violations in the next runtime release.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.11/dist-packages/google/protobuf/runtime_version.py:98: UserWarning: Protobuf gencode version 5.28.3 is exactly one major version older than the runtime version 6.31.1 at tensorflow/core/framework/graph_debug_info.proto. Please update the gencode to avoid compatibility violations in the next runtime release.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.11/dist-packages/google/protobuf/runtime_version.py:98: UserWarning: Protobuf gencode version 5.28.3 is exactly one major version older than the runtime version 6.31.1 at tensorflow/core/framework/versions.proto. Please update the gencode to avoid compatibility violations in the next runtime release.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.11/dist-packages/google/protobuf/runtime_version.py:98: UserWarning: Protobuf gencode version 5.28.3 is exactly one major version older than the runtime version 6.31.1 at tensorflow/core/protobuf/config.proto. Please update the gencode to avoid compatibility violations in the next runtime release.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.11/dist-packages/google/protobuf/runtime_version.py:98: UserWarning: Protobuf gencode version 5.28.3 is exactly one major version older than the runtime version 6.31.1 at xla/tsl/protobuf/coordination_config.proto. Please update the gencode to avoid compatibility violations in the next runtime release.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.11/dist-packages/google/protobuf/runtime_version.py:98: UserWarning: Protobuf gencode version 5.28.3 is exactly one major version older than the runtime version 6.31.1 at tensorflow/core/framework/cost_graph.proto. Please update the gencode to avoid compatibility violations in the next runtime release.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.11/dist-packages/google/protobuf/runtime_version.py:98: UserWarning: Protobuf gencode version 5.28.3 is exactly one major version older than the runtime version 6.31.1 at tensorflow/core/framework/step_stats.proto. Please update the gencode to avoid compatibility violations in the next runtime release.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.11/dist-packages/google/protobuf/runtime_version.py:98: UserWarning: Protobuf gencode version 5.28.3 is exactly one major version older than the runtime version 6.31.1 at tensorflow/core/framework/allocation_description.proto. Please update the gencode to avoid compatibility violations in the next runtime release.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.11/dist-packages/google/protobuf/runtime_version.py:98: UserWarning: Protobuf gencode version 5.28.3 is exactly one major version older than the runtime version 6.31.1 at tensorflow/core/framework/tensor_description.proto. Please update the gencode to avoid compatibility violations in the next runtime release.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.11/dist-packages/google/protobuf/runtime_version.py:98: UserWarning: Protobuf gencode version 5.28.3 is exactly one major version older than the runtime version 6.31.1 at tensorflow/core/protobuf/cluster.proto. Please update the gencode to avoid compatibility violations in the next runtime release.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.11/dist-packages/google/protobuf/runtime_version.py:98: UserWarning: Protobuf gencode version 5.28.3 is exactly one major version older than the runtime version 6.31.1 at tensorflow/core/protobuf/debug.proto. Please update the gencode to avoid compatibility violations in the next runtime release.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "import requests\n",
    "import zipfile\n",
    "import os\n",
    "import time\n",
    "import psutil\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torchvision import transforms, models\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n",
      "GPU Name: NVIDIA RTX 6000 Ada Generation\n"
     ]
    }
   ],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(f'Using device: {device}')\n",
    "if device.type == 'cuda':\n",
    "    print(f'GPU Name: {torch.cuda.get_device_name(0)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Chargement du dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def telecharger_dezip(url, chemin_sauv=\"plant_village_dataset.zip\", extract_path=\".\"):\n",
    "    print(\" Début du téléchargement\")\n",
    "    try:\n",
    "        response=requests.get(url, stream=True)\n",
    "        response.raise_for_status()\n",
    "\n",
    "        #Taille totale du fichier pour la barre de progression\n",
    "        total_size=int(response.headers.get('content-length',0))\n",
    "        block_size=1064\n",
    "        bar_progression = tqdm(total=total_size, unit='iB', unit_scale=True)\n",
    "\n",
    "        #Téléchargement\n",
    "        with open(chemin_sauv, 'wb') as file:\n",
    "            for data in response.iter_content(block_size):\n",
    "                bar_progression.update(len(data))\n",
    "                file.write(data)\n",
    "        bar_progression.close()\n",
    "\n",
    "        if total_size != 0 and bar_progression.n != total_size:\n",
    "            print(\"ERREUR, quelque chose s'est mal passé pendant le téléchargement.\")\n",
    "            return\n",
    "\n",
    "        print(f\"Téléchargement terminé. Fichier sauvegardé sous : {chemin_sauv}\")\n",
    "\n",
    "        # Créer le dossier d'extraction s'il n'existe pas\n",
    "        if not os.path.exists(extract_path):\n",
    "            os.makedirs(extract_path)\n",
    "\n",
    "        # Décompresser le fichier ZIP\n",
    "        print(f\"Décompression du fichier dans le dossier : {extract_path}\")\n",
    "        with zipfile.ZipFile(chemin_sauv, 'r') as zip_ref:\n",
    "            zip_ref.extractall(extract_path)\n",
    "\n",
    "        print(\"Décompression terminée.\")\n",
    "\n",
    "        # Optionnel : Supprimer le fichier .zip après extraction pour économiser de l'espace\n",
    "        print(f\"Suppression du fichier {chemin_sauv}...\")\n",
    "        os.remove(chemin_sauv)\n",
    "        print(\"Opération terminée avec succès !\")\n",
    "\n",
    "    except requests.exceptions.RequestException as e:\n",
    "        print(f\"Une erreur de réseau est survenue: {e}\")\n",
    "    except zipfile.BadZipFile:\n",
    "        print(\"Erreur: Le fichier téléchargé n'est pas un fichier ZIP valide.\")\n",
    "    except Exception as e:\n",
    "        print(f\"Une erreur inattendue est survenue: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "URL = \"https://data.mendeley.com/datasets/tywbtsjrjv/1/files/b4e3a32f-c0bd-4060-81e9-6144231f2520/file_downloaded\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "extract_folder = \"plant_village_dataset\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Début du téléchargement\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 949M/949M [00:41<00:00, 23.0MiB/s]  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Téléchargement terminé. Fichier sauvegardé sous : PlantVillage.zip\n",
      "Décompression du fichier dans le dossier : plant_village_dataset\n",
      "Décompression terminée.\n",
      "Suppression du fichier PlantVillage.zip...\n",
      "Opération terminée avec succès !\n"
     ]
    }
   ],
   "source": [
    "telecharger_dezip(URL, \"PlantVillage.zip\", extract_folder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "path=\"/workspace/plant_village_dataset/Plant_leave_diseases_dataset_with_augmentation\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "IMG_SIZE = (224, 224)\n",
    "BATCH_SIZE = 32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_gen=ImageDataGenerator(rescale=1./255)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 61486 images belonging to 39 classes.\n"
     ]
    }
   ],
   "source": [
    "data=data_gen.flow_from_directory(\n",
    "    path,\n",
    "    target_size=IMG_SIZE,\n",
    "    batch_size=BATCH_SIZE,\n",
    "    class_mode=\"categorical\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MODELISATION"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## VGG19"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total des images trouvées : 61486\n"
     ]
    }
   ],
   "source": [
    "# --------- 1. Préparer les données ---------\n",
    "filepaths = []\n",
    "labels = []\n",
    "folds = os.listdir(path)\n",
    "for fold in folds:\n",
    "    f_path = os.path.join(path, fold)\n",
    "    if not os.path.isdir(f_path):\n",
    "        continue\n",
    "    for file in os.listdir(f_path):\n",
    "        filepaths.append(os.path.join(f_path, file))\n",
    "        labels.append(fold)\n",
    "\n",
    "df = pd.DataFrame({'filepaths': filepaths, 'labels': labels})\n",
    "print(f\"Total des images trouvées : {len(df)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split 80/20 avec stratification\n",
    "train_df, test_df = train_test_split(\n",
    "    df,\n",
    "    test_size=0.1,\n",
    "    random_state=42,\n",
    "    stratify=df['labels']\n",
    ")\n",
    "train_df, val_df = train_test_split(\n",
    "    train_df,\n",
    "    test_size=0.2,\n",
    "    random_state=42,\n",
    "    stratify=train_df['labels']\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Mapping des classes en indices\n",
    "class_names = sorted(df['labels'].unique())\n",
    "class_to_idx = {cls: idx for idx, cls in enumerate(class_names)}\n",
    "num_classes = len(class_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# --------- 2. Dataset personnalisé ---------\n",
    "class CustomImageDataset(Dataset):\n",
    "    def __init__(self, df, class_to_idx, transform=None):\n",
    "        self.df = df.reset_index(drop=True)\n",
    "        self.class_to_idx = class_to_idx\n",
    "        self.transform = transform\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.df)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        img_path = self.df.loc[idx, 'filepaths']\n",
    "        label_name = self.df.loc[idx, 'labels']\n",
    "        label = self.class_to_idx[label_name]\n",
    "        \n",
    "        image = Image.open(img_path).convert('RGB')\n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "        return image, label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# --------- 3. Data augmentation et loaders ---------\n",
    "train_transforms = transforms.Compose([\n",
    "    transforms.Resize(IMG_SIZE),\n",
    "    transforms.RandomRotation(30),\n",
    "    transforms.RandomHorizontalFlip(),\n",
    "    transforms.ColorJitter(brightness=0.2, contrast=0.2),\n",
    "    transforms.RandomResizedCrop(IMG_SIZE),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406],\n",
    "                         std=[0.229, 0.224, 0.225])\n",
    "])\n",
    "\n",
    "val_transforms = transforms.Compose([\n",
    "    transforms.Resize(IMG_SIZE),\n",
    "    transforms.CenterCrop(IMG_SIZE),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406],\n",
    "                         std=[0.229, 0.224, 0.225])\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = CustomImageDataset(train_df, class_to_idx, transform=train_transforms)\n",
    "val_dataset = CustomImageDataset(val_df, class_to_idx, transform=val_transforms)\n",
    "test_dataset = CustomImageDataset(test_df, class_to_idx, transform=val_transforms)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader = DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=True, num_workers=4)\n",
    "val_loader = DataLoader(val_dataset, batch_size=BATCH_SIZE, shuffle=False, num_workers=4)\n",
    "test_loader = DataLoader(test_dataset, batch_size=BATCH_SIZE, shuffle=False, num_workers=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Charger le modèle MobileNetV2 pré-entraîné\n",
    "model = models.mobilenet_v2(weights=models.MobileNet_V2_Weights.DEFAULT)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "for param in model.parameters():\n",
    "    param.requires_grad = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Modifier le classificateur final pour notre nombre de classes\n",
    "num_ftrs = model.classifier[1].in_features\n",
    "model.classifier[1] = nn.Linear(num_ftrs, num_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = optim.Adam(model.classifier[1].parameters(), lr=0.001)\n",
    "scheduler = optim.lr_scheduler.StepLR(optimizer, step_size=7, gamma=0.1)\n",
    "criterion = nn.CrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(model, criterion, optimizer, scheduler, num_epochs, train_loader, val_loader, device):\n",
    "    best_val_accuracy = 0.0\n",
    "    best_model_path = '/workspace/models/best_mobilenetv2_model.pth'\n",
    "    start_time = time.time()\n",
    "    \n",
    "    for epoch in range(num_epochs):\n",
    "        epoch_start_time = time.time()\n",
    "        \n",
    "        # Phase d'entraînement\n",
    "        model.train()\n",
    "        train_loss = 0.0\n",
    "        train_corrects = 0\n",
    "        \n",
    "        for inputs, labels in tqdm(train_loader, desc=f\"Training Epoch {epoch+1}/{num_epochs}\"):\n",
    "            inputs, labels = inputs.to(device), labels.to(device)\n",
    "            \n",
    "            optimizer.zero_grad()\n",
    "            \n",
    "            outputs = model(inputs)\n",
    "            _, preds = torch.max(outputs, 1)\n",
    "            loss = criterion(outputs, labels)\n",
    "            \n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            \n",
    "            train_loss += loss.item() * inputs.size(0)\n",
    "            train_corrects += torch.sum(preds == labels.data)\n",
    "            \n",
    "        scheduler.step()\n",
    "        \n",
    "        train_loss = train_loss / len(train_loader.dataset)\n",
    "        train_accuracy = train_corrects.double() / len(train_loader.dataset)\n",
    "        \n",
    "        # Phase de validation\n",
    "        model.eval()\n",
    "        val_loss = 0.0\n",
    "        val_corrects = 0\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            for inputs, labels in tqdm(val_loader, desc=f\"Validation Epoch {epoch+1}/{num_epochs}\"):\n",
    "                inputs, labels = inputs.to(device), labels.to(device)\n",
    "                \n",
    "                outputs = model(inputs)\n",
    "                _, preds = torch.max(outputs, 1)\n",
    "                loss = criterion(outputs, labels)\n",
    "                \n",
    "                val_loss += loss.item() * inputs.size(0)\n",
    "                val_corrects += torch.sum(preds == labels.data)\n",
    "        \n",
    "        val_loss = val_loss / len(val_loader.dataset)\n",
    "        val_accuracy = val_corrects.double() / len(val_loader.dataset)\n",
    "        \n",
    "        # Affichage des métriques de performance\n",
    "        print(f'Epoch {epoch+1}/{num_epochs} - '\n",
    "              f'Temps: {time.time()-epoch_start_time:.2f}s | '\n",
    "              f'Train Loss: {train_loss:.4f} Acc: {train_accuracy:.4f} | '\n",
    "              f'Val Loss: {val_loss:.4f} Acc: {val_accuracy:.4f}')\n",
    "\n",
    "        # Sauvegarde du meilleur modèle\n",
    "        if val_accuracy > best_val_accuracy:\n",
    "            best_val_accuracy = val_accuracy\n",
    "            torch.save(model.state_dict(), best_model_path)\n",
    "            print(f'Meilleur modèle sauvegardé avec une précision de validation de {best_val_accuracy:.4f}')\n",
    "            \n",
    "    total_time = time.time() - start_time\n",
    "    print(f'Formation terminée en {total_time:.2f} secondes.')\n",
    "    print(f'Meilleure précision de validation : {best_val_accuracy:.4f}')\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 1/20: 100%|██████████| 1384/1384 [01:10<00:00, 19.72it/s]\n",
      "Validation Epoch 1/20: 100%|██████████| 346/346 [00:14<00:00, 23.62it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20 - Temps: 84.86s | Train Loss: 1.2087 Acc: 0.7027 | Val Loss: 0.6486 Acc: 0.8505\n",
      "Meilleur modèle sauvegardé avec une précision de validation de 0.8505\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 2/20: 100%|██████████| 1384/1384 [01:09<00:00, 20.05it/s]\n",
      "Validation Epoch 2/20: 100%|██████████| 346/346 [00:13<00:00, 24.97it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2/20 - Temps: 82.91s | Train Loss: 0.7090 Acc: 0.8027 | Val Loss: 0.5290 Acc: 0.8641\n",
      "Meilleur modèle sauvegardé avec une précision de validation de 0.8641\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 3/20: 100%|██████████| 1384/1384 [01:11<00:00, 19.24it/s]\n",
      "Validation Epoch 3/20: 100%|██████████| 346/346 [00:14<00:00, 24.23it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3/20 - Temps: 86.22s | Train Loss: 0.6267 Acc: 0.8178 | Val Loss: 0.4558 Acc: 0.8844\n",
      "Meilleur modèle sauvegardé avec une précision de validation de 0.8844\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 4/20: 100%|██████████| 1384/1384 [01:10<00:00, 19.75it/s]\n",
      "Validation Epoch 4/20: 100%|██████████| 346/346 [00:13<00:00, 24.77it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4/20 - Temps: 84.06s | Train Loss: 0.5931 Acc: 0.8241 | Val Loss: 0.4056 Acc: 0.8944\n",
      "Meilleur modèle sauvegardé avec une précision de validation de 0.8944\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 5/20: 100%|██████████| 1384/1384 [01:11<00:00, 19.25it/s]\n",
      "Validation Epoch 5/20: 100%|██████████| 346/346 [00:15<00:00, 22.82it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5/20 - Temps: 87.07s | Train Loss: 0.5817 Acc: 0.8233 | Val Loss: 0.4138 Acc: 0.8904\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 6/20: 100%|██████████| 1384/1384 [01:15<00:00, 18.38it/s]\n",
      "Validation Epoch 6/20: 100%|██████████| 346/346 [00:17<00:00, 20.24it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6/20 - Temps: 92.40s | Train Loss: 0.5678 Acc: 0.8309 | Val Loss: 0.3976 Acc: 0.8950\n",
      "Meilleur modèle sauvegardé avec une précision de validation de 0.8950\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 7/20: 100%|██████████| 1384/1384 [01:34<00:00, 14.69it/s]\n",
      "Validation Epoch 7/20: 100%|██████████| 346/346 [00:21<00:00, 16.45it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 7/20 - Temps: 115.23s | Train Loss: 0.5587 Acc: 0.8327 | Val Loss: 0.3535 Acc: 0.8999\n",
      "Meilleur modèle sauvegardé avec une précision de validation de 0.8999\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 8/20: 100%|██████████| 1384/1384 [01:18<00:00, 17.72it/s]\n",
      "Validation Epoch 8/20: 100%|██████████| 346/346 [00:15<00:00, 22.78it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 8/20 - Temps: 93.30s | Train Loss: 0.5317 Acc: 0.8403 | Val Loss: 0.3337 Acc: 0.9078\n",
      "Meilleur modèle sauvegardé avec une précision de validation de 0.9078\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 9/20: 100%|██████████| 1384/1384 [01:11<00:00, 19.48it/s]\n",
      "Validation Epoch 9/20: 100%|██████████| 346/346 [00:14<00:00, 24.67it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9/20 - Temps: 85.11s | Train Loss: 0.5210 Acc: 0.8417 | Val Loss: 0.3200 Acc: 0.9127\n",
      "Meilleur modèle sauvegardé avec une précision de validation de 0.9127\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 10/20: 100%|██████████| 1384/1384 [01:10<00:00, 19.70it/s]\n",
      "Validation Epoch 10/20: 100%|██████████| 346/346 [00:14<00:00, 23.58it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 10/20 - Temps: 84.95s | Train Loss: 0.5255 Acc: 0.8413 | Val Loss: 0.3263 Acc: 0.9126\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 11/20: 100%|██████████| 1384/1384 [01:08<00:00, 20.07it/s]\n",
      "Validation Epoch 11/20: 100%|██████████| 346/346 [00:13<00:00, 24.73it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 11/20 - Temps: 82.96s | Train Loss: 0.5190 Acc: 0.8420 | Val Loss: 0.3653 Acc: 0.9026\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 12/20: 100%|██████████| 1384/1384 [01:06<00:00, 20.92it/s]\n",
      "Validation Epoch 12/20: 100%|██████████| 346/346 [00:13<00:00, 25.52it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 12/20 - Temps: 79.74s | Train Loss: 0.5106 Acc: 0.8455 | Val Loss: 0.3461 Acc: 0.9050\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 13/20: 100%|██████████| 1384/1384 [01:08<00:00, 20.06it/s]\n",
      "Validation Epoch 13/20: 100%|██████████| 346/346 [00:14<00:00, 23.93it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 13/20 - Temps: 83.46s | Train Loss: 0.5196 Acc: 0.8428 | Val Loss: 0.3099 Acc: 0.9164\n",
      "Meilleur modèle sauvegardé avec une précision de validation de 0.9164\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 14/20: 100%|██████████| 1384/1384 [01:12<00:00, 19.15it/s]\n",
      "Validation Epoch 14/20: 100%|██████████| 346/346 [00:14<00:00, 23.24it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 14/20 - Temps: 87.17s | Train Loss: 0.5125 Acc: 0.8450 | Val Loss: 0.3388 Acc: 0.9087\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 15/20: 100%|██████████| 1384/1384 [01:12<00:00, 19.03it/s]\n",
      "Validation Epoch 15/20: 100%|██████████| 346/346 [00:14<00:00, 23.72it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 15/20 - Temps: 87.34s | Train Loss: 0.5196 Acc: 0.8432 | Val Loss: 0.3229 Acc: 0.9119\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 16/20: 100%|██████████| 1384/1384 [01:10<00:00, 19.59it/s]\n",
      "Validation Epoch 16/20: 100%|██████████| 346/346 [00:12<00:00, 27.15it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 16/20 - Temps: 83.40s | Train Loss: 0.5142 Acc: 0.8475 | Val Loss: 0.3277 Acc: 0.9134\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 17/20: 100%|██████████| 1384/1384 [01:08<00:00, 20.18it/s]\n",
      "Validation Epoch 17/20: 100%|██████████| 346/346 [00:14<00:00, 23.50it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 17/20 - Temps: 83.31s | Train Loss: 0.5179 Acc: 0.8430 | Val Loss: 0.3406 Acc: 0.9074\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 18/20: 100%|██████████| 1384/1384 [01:09<00:00, 19.98it/s]\n",
      "Validation Epoch 18/20: 100%|██████████| 346/346 [00:13<00:00, 25.25it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 18/20 - Temps: 82.97s | Train Loss: 0.5207 Acc: 0.8408 | Val Loss: 0.3420 Acc: 0.9096\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 19/20: 100%|██████████| 1384/1384 [01:09<00:00, 19.98it/s]\n",
      "Validation Epoch 19/20: 100%|██████████| 346/346 [00:14<00:00, 23.39it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 19/20 - Temps: 84.08s | Train Loss: 0.5091 Acc: 0.8446 | Val Loss: 0.3559 Acc: 0.9046\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 20/20: 100%|██████████| 1384/1384 [01:07<00:00, 20.49it/s]\n",
      "Validation Epoch 20/20: 100%|██████████| 346/346 [00:13<00:00, 25.79it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 20/20 - Temps: 80.97s | Train Loss: 0.5119 Acc: 0.8452 | Val Loss: 0.3036 Acc: 0.9186\n",
      "Meilleur modèle sauvegardé avec une précision de validation de 0.9186\n",
      "Formation terminée en 1732.25 secondes.\n",
      "Meilleure précision de validation : 0.9186\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "NUM_EPOCHS = 20\n",
    "trained_model = train_model(model, criterion, optimizer, scheduler, NUM_EPOCHS, train_loader, val_loader, device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MobileNetV2(\n",
       "  (features): Sequential(\n",
       "    (0): Conv2dNormActivation(\n",
       "      (0): Conv2d(3, 32, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (2): ReLU6(inplace=True)\n",
       "    )\n",
       "    (1): InvertedResidual(\n",
       "      (conv): Sequential(\n",
       "        (0): Conv2dNormActivation(\n",
       "          (0): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False)\n",
       "          (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): ReLU6(inplace=True)\n",
       "        )\n",
       "        (1): Conv2d(32, 16, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (2): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (2): InvertedResidual(\n",
       "      (conv): Sequential(\n",
       "        (0): Conv2dNormActivation(\n",
       "          (0): Conv2d(16, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (1): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): ReLU6(inplace=True)\n",
       "        )\n",
       "        (1): Conv2dNormActivation(\n",
       "          (0): Conv2d(96, 96, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=96, bias=False)\n",
       "          (1): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): ReLU6(inplace=True)\n",
       "        )\n",
       "        (2): Conv2d(96, 24, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (3): BatchNorm2d(24, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (3): InvertedResidual(\n",
       "      (conv): Sequential(\n",
       "        (0): Conv2dNormActivation(\n",
       "          (0): Conv2d(24, 144, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (1): BatchNorm2d(144, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): ReLU6(inplace=True)\n",
       "        )\n",
       "        (1): Conv2dNormActivation(\n",
       "          (0): Conv2d(144, 144, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=144, bias=False)\n",
       "          (1): BatchNorm2d(144, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): ReLU6(inplace=True)\n",
       "        )\n",
       "        (2): Conv2d(144, 24, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (3): BatchNorm2d(24, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (4): InvertedResidual(\n",
       "      (conv): Sequential(\n",
       "        (0): Conv2dNormActivation(\n",
       "          (0): Conv2d(24, 144, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (1): BatchNorm2d(144, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): ReLU6(inplace=True)\n",
       "        )\n",
       "        (1): Conv2dNormActivation(\n",
       "          (0): Conv2d(144, 144, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=144, bias=False)\n",
       "          (1): BatchNorm2d(144, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): ReLU6(inplace=True)\n",
       "        )\n",
       "        (2): Conv2d(144, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (3): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (5): InvertedResidual(\n",
       "      (conv): Sequential(\n",
       "        (0): Conv2dNormActivation(\n",
       "          (0): Conv2d(32, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (1): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): ReLU6(inplace=True)\n",
       "        )\n",
       "        (1): Conv2dNormActivation(\n",
       "          (0): Conv2d(192, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=192, bias=False)\n",
       "          (1): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): ReLU6(inplace=True)\n",
       "        )\n",
       "        (2): Conv2d(192, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (3): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (6): InvertedResidual(\n",
       "      (conv): Sequential(\n",
       "        (0): Conv2dNormActivation(\n",
       "          (0): Conv2d(32, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (1): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): ReLU6(inplace=True)\n",
       "        )\n",
       "        (1): Conv2dNormActivation(\n",
       "          (0): Conv2d(192, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=192, bias=False)\n",
       "          (1): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): ReLU6(inplace=True)\n",
       "        )\n",
       "        (2): Conv2d(192, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (3): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (7): InvertedResidual(\n",
       "      (conv): Sequential(\n",
       "        (0): Conv2dNormActivation(\n",
       "          (0): Conv2d(32, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (1): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): ReLU6(inplace=True)\n",
       "        )\n",
       "        (1): Conv2dNormActivation(\n",
       "          (0): Conv2d(192, 192, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=192, bias=False)\n",
       "          (1): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): ReLU6(inplace=True)\n",
       "        )\n",
       "        (2): Conv2d(192, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (3): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (8): InvertedResidual(\n",
       "      (conv): Sequential(\n",
       "        (0): Conv2dNormActivation(\n",
       "          (0): Conv2d(64, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (1): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): ReLU6(inplace=True)\n",
       "        )\n",
       "        (1): Conv2dNormActivation(\n",
       "          (0): Conv2d(384, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=384, bias=False)\n",
       "          (1): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): ReLU6(inplace=True)\n",
       "        )\n",
       "        (2): Conv2d(384, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (3): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (9): InvertedResidual(\n",
       "      (conv): Sequential(\n",
       "        (0): Conv2dNormActivation(\n",
       "          (0): Conv2d(64, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (1): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): ReLU6(inplace=True)\n",
       "        )\n",
       "        (1): Conv2dNormActivation(\n",
       "          (0): Conv2d(384, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=384, bias=False)\n",
       "          (1): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): ReLU6(inplace=True)\n",
       "        )\n",
       "        (2): Conv2d(384, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (3): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (10): InvertedResidual(\n",
       "      (conv): Sequential(\n",
       "        (0): Conv2dNormActivation(\n",
       "          (0): Conv2d(64, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (1): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): ReLU6(inplace=True)\n",
       "        )\n",
       "        (1): Conv2dNormActivation(\n",
       "          (0): Conv2d(384, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=384, bias=False)\n",
       "          (1): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): ReLU6(inplace=True)\n",
       "        )\n",
       "        (2): Conv2d(384, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (3): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (11): InvertedResidual(\n",
       "      (conv): Sequential(\n",
       "        (0): Conv2dNormActivation(\n",
       "          (0): Conv2d(64, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (1): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): ReLU6(inplace=True)\n",
       "        )\n",
       "        (1): Conv2dNormActivation(\n",
       "          (0): Conv2d(384, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=384, bias=False)\n",
       "          (1): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): ReLU6(inplace=True)\n",
       "        )\n",
       "        (2): Conv2d(384, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (3): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (12): InvertedResidual(\n",
       "      (conv): Sequential(\n",
       "        (0): Conv2dNormActivation(\n",
       "          (0): Conv2d(96, 576, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (1): BatchNorm2d(576, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): ReLU6(inplace=True)\n",
       "        )\n",
       "        (1): Conv2dNormActivation(\n",
       "          (0): Conv2d(576, 576, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=576, bias=False)\n",
       "          (1): BatchNorm2d(576, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): ReLU6(inplace=True)\n",
       "        )\n",
       "        (2): Conv2d(576, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (3): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (13): InvertedResidual(\n",
       "      (conv): Sequential(\n",
       "        (0): Conv2dNormActivation(\n",
       "          (0): Conv2d(96, 576, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (1): BatchNorm2d(576, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): ReLU6(inplace=True)\n",
       "        )\n",
       "        (1): Conv2dNormActivation(\n",
       "          (0): Conv2d(576, 576, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=576, bias=False)\n",
       "          (1): BatchNorm2d(576, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): ReLU6(inplace=True)\n",
       "        )\n",
       "        (2): Conv2d(576, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (3): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (14): InvertedResidual(\n",
       "      (conv): Sequential(\n",
       "        (0): Conv2dNormActivation(\n",
       "          (0): Conv2d(96, 576, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (1): BatchNorm2d(576, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): ReLU6(inplace=True)\n",
       "        )\n",
       "        (1): Conv2dNormActivation(\n",
       "          (0): Conv2d(576, 576, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=576, bias=False)\n",
       "          (1): BatchNorm2d(576, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): ReLU6(inplace=True)\n",
       "        )\n",
       "        (2): Conv2d(576, 160, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (3): BatchNorm2d(160, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (15): InvertedResidual(\n",
       "      (conv): Sequential(\n",
       "        (0): Conv2dNormActivation(\n",
       "          (0): Conv2d(160, 960, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (1): BatchNorm2d(960, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): ReLU6(inplace=True)\n",
       "        )\n",
       "        (1): Conv2dNormActivation(\n",
       "          (0): Conv2d(960, 960, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=960, bias=False)\n",
       "          (1): BatchNorm2d(960, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): ReLU6(inplace=True)\n",
       "        )\n",
       "        (2): Conv2d(960, 160, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (3): BatchNorm2d(160, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (16): InvertedResidual(\n",
       "      (conv): Sequential(\n",
       "        (0): Conv2dNormActivation(\n",
       "          (0): Conv2d(160, 960, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (1): BatchNorm2d(960, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): ReLU6(inplace=True)\n",
       "        )\n",
       "        (1): Conv2dNormActivation(\n",
       "          (0): Conv2d(960, 960, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=960, bias=False)\n",
       "          (1): BatchNorm2d(960, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): ReLU6(inplace=True)\n",
       "        )\n",
       "        (2): Conv2d(960, 160, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (3): BatchNorm2d(160, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (17): InvertedResidual(\n",
       "      (conv): Sequential(\n",
       "        (0): Conv2dNormActivation(\n",
       "          (0): Conv2d(160, 960, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (1): BatchNorm2d(960, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): ReLU6(inplace=True)\n",
       "        )\n",
       "        (1): Conv2dNormActivation(\n",
       "          (0): Conv2d(960, 960, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=960, bias=False)\n",
       "          (1): BatchNorm2d(960, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): ReLU6(inplace=True)\n",
       "        )\n",
       "        (2): Conv2d(960, 320, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (3): BatchNorm2d(320, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (18): Conv2dNormActivation(\n",
       "      (0): Conv2d(320, 1280, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (1): BatchNorm2d(1280, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (2): ReLU6(inplace=True)\n",
       "    )\n",
       "  )\n",
       "  (classifier): Sequential(\n",
       "    (0): Dropout(p=0.2, inplace=False)\n",
       "    (1): Linear(in_features=1280, out_features=39, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trained_model.load_state_dict(torch.load('/workspace/models/best_mobilenetv2_model.pth'))\n",
    "trained_model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_preds = []\n",
    "all_labels = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Batch 1] Time: 0.02s | CPU: 8.5% | RAM: 130.66GB | GPU: 44.09MB\n",
      "[Batch 2] Time: 0.01s | CPU: 37.7% | RAM: 130.68GB | GPU: 44.09MB\n",
      "[Batch 3] Time: 0.01s | CPU: 11.0% | RAM: 130.70GB | GPU: 44.09MB\n",
      "[Batch 4] Time: 0.01s | CPU: 7.9% | RAM: 130.69GB | GPU: 44.09MB\n",
      "[Batch 5] Time: 0.01s | CPU: 19.1% | RAM: 130.69GB | GPU: 44.09MB\n",
      "[Batch 6] Time: 0.01s | CPU: 15.0% | RAM: 130.70GB | GPU: 44.09MB\n",
      "[Batch 7] Time: 0.01s | CPU: 7.1% | RAM: 130.70GB | GPU: 44.09MB\n",
      "[Batch 8] Time: 0.01s | CPU: 6.3% | RAM: 130.70GB | GPU: 44.09MB\n",
      "[Batch 9] Time: 0.02s | CPU: 17.9% | RAM: 130.70GB | GPU: 44.09MB\n",
      "[Batch 10] Time: 0.01s | CPU: 7.9% | RAM: 130.71GB | GPU: 44.09MB\n",
      "[Batch 11] Time: 0.01s | CPU: 8.0% | RAM: 130.69GB | GPU: 44.09MB\n",
      "[Batch 12] Time: 0.01s | CPU: 20.5% | RAM: 130.70GB | GPU: 44.09MB\n",
      "[Batch 13] Time: 0.01s | CPU: 14.1% | RAM: 130.71GB | GPU: 44.09MB\n",
      "[Batch 14] Time: 0.01s | CPU: 19.3% | RAM: 130.71GB | GPU: 44.09MB\n",
      "[Batch 15] Time: 0.01s | CPU: 24.6% | RAM: 130.72GB | GPU: 44.09MB\n",
      "[Batch 16] Time: 0.02s | CPU: 16.7% | RAM: 130.73GB | GPU: 44.09MB\n",
      "[Batch 17] Time: 0.01s | CPU: 14.4% | RAM: 130.74GB | GPU: 44.09MB\n",
      "[Batch 18] Time: 0.01s | CPU: 6.5% | RAM: 130.74GB | GPU: 44.09MB\n",
      "[Batch 19] Time: 0.01s | CPU: 5.9% | RAM: 130.74GB | GPU: 44.09MB\n",
      "[Batch 20] Time: 0.01s | CPU: 24.9% | RAM: 130.72GB | GPU: 44.09MB\n",
      "[Batch 21] Time: 0.01s | CPU: 22.9% | RAM: 130.73GB | GPU: 44.09MB\n",
      "[Batch 22] Time: 0.01s | CPU: 7.2% | RAM: 130.74GB | GPU: 44.09MB\n",
      "[Batch 23] Time: 0.01s | CPU: 7.8% | RAM: 130.75GB | GPU: 44.09MB\n",
      "[Batch 24] Time: 0.01s | CPU: 11.2% | RAM: 130.74GB | GPU: 44.09MB\n",
      "[Batch 25] Time: 0.01s | CPU: 21.0% | RAM: 130.75GB | GPU: 44.09MB\n",
      "[Batch 26] Time: 0.01s | CPU: 6.5% | RAM: 130.76GB | GPU: 44.09MB\n",
      "[Batch 27] Time: 0.01s | CPU: 6.7% | RAM: 130.76GB | GPU: 44.09MB\n",
      "[Batch 28] Time: 0.01s | CPU: 5.8% | RAM: 130.77GB | GPU: 44.09MB\n",
      "[Batch 29] Time: 0.01s | CPU: 21.6% | RAM: 130.75GB | GPU: 44.09MB\n",
      "[Batch 30] Time: 0.01s | CPU: 6.5% | RAM: 130.73GB | GPU: 44.09MB\n",
      "[Batch 31] Time: 0.01s | CPU: 6.6% | RAM: 130.73GB | GPU: 44.09MB\n",
      "[Batch 32] Time: 0.01s | CPU: 12.0% | RAM: 130.75GB | GPU: 44.09MB\n",
      "[Batch 33] Time: 0.01s | CPU: 17.1% | RAM: 130.76GB | GPU: 44.09MB\n",
      "[Batch 34] Time: 0.01s | CPU: 52.1% | RAM: 130.76GB | GPU: 44.09MB\n",
      "[Batch 35] Time: 0.01s | CPU: 15.4% | RAM: 130.77GB | GPU: 44.09MB\n",
      "[Batch 36] Time: 0.01s | CPU: 6.2% | RAM: 130.76GB | GPU: 44.09MB\n",
      "[Batch 37] Time: 0.01s | CPU: 15.9% | RAM: 130.76GB | GPU: 44.09MB\n",
      "[Batch 38] Time: 0.01s | CPU: 6.0% | RAM: 130.76GB | GPU: 44.09MB\n",
      "[Batch 39] Time: 0.01s | CPU: 11.1% | RAM: 130.77GB | GPU: 44.09MB\n",
      "[Batch 40] Time: 0.01s | CPU: 15.5% | RAM: 130.77GB | GPU: 44.09MB\n",
      "[Batch 41] Time: 0.01s | CPU: 16.2% | RAM: 130.77GB | GPU: 44.09MB\n",
      "[Batch 42] Time: 0.01s | CPU: 36.3% | RAM: 130.77GB | GPU: 44.09MB\n",
      "[Batch 43] Time: 0.01s | CPU: 10.6% | RAM: 130.77GB | GPU: 44.09MB\n",
      "[Batch 44] Time: 0.01s | CPU: 4.8% | RAM: 130.77GB | GPU: 44.09MB\n",
      "[Batch 45] Time: 0.01s | CPU: 16.4% | RAM: 130.76GB | GPU: 44.09MB\n",
      "[Batch 46] Time: 0.01s | CPU: 21.1% | RAM: 130.76GB | GPU: 44.09MB\n",
      "[Batch 47] Time: 0.01s | CPU: 15.5% | RAM: 130.80GB | GPU: 44.09MB\n",
      "[Batch 48] Time: 0.01s | CPU: 7.2% | RAM: 130.82GB | GPU: 44.09MB\n",
      "[Batch 49] Time: 0.01s | CPU: 29.4% | RAM: 130.82GB | GPU: 44.09MB\n",
      "[Batch 50] Time: 0.01s | CPU: 26.4% | RAM: 130.82GB | GPU: 44.09MB\n",
      "[Batch 51] Time: 0.01s | CPU: 16.2% | RAM: 130.84GB | GPU: 44.09MB\n",
      "[Batch 52] Time: 0.01s | CPU: 7.3% | RAM: 130.82GB | GPU: 44.09MB\n",
      "[Batch 53] Time: 0.01s | CPU: 8.6% | RAM: 130.81GB | GPU: 44.09MB\n",
      "[Batch 54] Time: 0.01s | CPU: 14.3% | RAM: 130.79GB | GPU: 44.09MB\n",
      "[Batch 55] Time: 0.01s | CPU: 21.4% | RAM: 130.79GB | GPU: 44.09MB\n",
      "[Batch 56] Time: 0.01s | CPU: 7.1% | RAM: 130.80GB | GPU: 44.09MB\n",
      "[Batch 57] Time: 0.01s | CPU: 19.9% | RAM: 130.78GB | GPU: 44.09MB\n",
      "[Batch 58] Time: 0.01s | CPU: 34.4% | RAM: 130.76GB | GPU: 44.09MB\n",
      "[Batch 59] Time: 0.01s | CPU: 13.9% | RAM: 130.80GB | GPU: 44.09MB\n",
      "[Batch 60] Time: 0.01s | CPU: 7.9% | RAM: 130.79GB | GPU: 44.09MB\n",
      "[Batch 61] Time: 0.01s | CPU: 25.3% | RAM: 130.81GB | GPU: 44.09MB\n",
      "[Batch 62] Time: 0.01s | CPU: 10.7% | RAM: 130.81GB | GPU: 44.09MB\n",
      "[Batch 63] Time: 0.01s | CPU: 12.9% | RAM: 130.83GB | GPU: 44.09MB\n",
      "[Batch 64] Time: 0.01s | CPU: 8.0% | RAM: 130.83GB | GPU: 44.09MB\n",
      "[Batch 65] Time: 0.01s | CPU: 23.7% | RAM: 130.80GB | GPU: 44.09MB\n",
      "[Batch 66] Time: 0.01s | CPU: 9.7% | RAM: 130.79GB | GPU: 44.09MB\n",
      "[Batch 67] Time: 0.01s | CPU: 16.6% | RAM: 130.81GB | GPU: 44.09MB\n",
      "[Batch 68] Time: 0.01s | CPU: 7.3% | RAM: 130.83GB | GPU: 44.09MB\n",
      "[Batch 69] Time: 0.01s | CPU: 24.5% | RAM: 130.83GB | GPU: 44.09MB\n",
      "[Batch 70] Time: 0.01s | CPU: 18.5% | RAM: 130.84GB | GPU: 44.09MB\n",
      "[Batch 71] Time: 0.01s | CPU: 9.2% | RAM: 130.86GB | GPU: 44.09MB\n",
      "[Batch 72] Time: 0.01s | CPU: 41.7% | RAM: 130.88GB | GPU: 44.09MB\n",
      "[Batch 73] Time: 0.01s | CPU: 14.7% | RAM: 130.85GB | GPU: 44.09MB\n",
      "[Batch 74] Time: 0.01s | CPU: 14.1% | RAM: 130.85GB | GPU: 44.09MB\n",
      "[Batch 75] Time: 0.01s | CPU: 21.9% | RAM: 130.88GB | GPU: 44.09MB\n",
      "[Batch 76] Time: 0.01s | CPU: 6.7% | RAM: 130.90GB | GPU: 44.09MB\n",
      "[Batch 77] Time: 0.01s | CPU: 12.3% | RAM: 130.89GB | GPU: 44.09MB\n",
      "[Batch 78] Time: 0.01s | CPU: 26.6% | RAM: 130.91GB | GPU: 44.09MB\n",
      "[Batch 79] Time: 0.01s | CPU: 22.9% | RAM: 130.91GB | GPU: 44.09MB\n",
      "[Batch 80] Time: 0.01s | CPU: 7.5% | RAM: 130.91GB | GPU: 44.09MB\n",
      "[Batch 81] Time: 0.01s | CPU: 21.1% | RAM: 130.91GB | GPU: 44.09MB\n",
      "[Batch 82] Time: 0.01s | CPU: 33.1% | RAM: 130.91GB | GPU: 44.09MB\n",
      "[Batch 83] Time: 0.01s | CPU: 13.9% | RAM: 130.91GB | GPU: 44.09MB\n",
      "[Batch 84] Time: 0.01s | CPU: 16.9% | RAM: 130.93GB | GPU: 44.09MB\n",
      "[Batch 85] Time: 0.01s | CPU: 12.0% | RAM: 131.11GB | GPU: 44.09MB\n",
      "[Batch 86] Time: 0.01s | CPU: 5.7% | RAM: 131.11GB | GPU: 44.09MB\n",
      "[Batch 87] Time: 0.01s | CPU: 17.4% | RAM: 131.21GB | GPU: 44.09MB\n",
      "[Batch 88] Time: 0.01s | CPU: 15.1% | RAM: 131.67GB | GPU: 44.09MB\n",
      "[Batch 89] Time: 0.01s | CPU: 26.4% | RAM: 132.16GB | GPU: 44.09MB\n",
      "[Batch 90] Time: 0.01s | CPU: 4.9% | RAM: 132.16GB | GPU: 44.09MB\n",
      "[Batch 91] Time: 0.01s | CPU: 5.3% | RAM: 132.16GB | GPU: 44.09MB\n",
      "[Batch 92] Time: 0.01s | CPU: 23.7% | RAM: 132.57GB | GPU: 44.09MB\n",
      "[Batch 93] Time: 0.01s | CPU: 5.0% | RAM: 132.58GB | GPU: 44.09MB\n",
      "[Batch 94] Time: 0.01s | CPU: 5.3% | RAM: 132.57GB | GPU: 44.09MB\n",
      "[Batch 95] Time: 0.01s | CPU: 5.3% | RAM: 132.57GB | GPU: 44.09MB\n",
      "[Batch 96] Time: 0.02s | CPU: 16.3% | RAM: 133.21GB | GPU: 44.09MB\n",
      "[Batch 97] Time: 0.01s | CPU: 10.9% | RAM: 133.28GB | GPU: 44.09MB\n",
      "[Batch 98] Time: 0.01s | CPU: 10.1% | RAM: 133.29GB | GPU: 44.09MB\n",
      "[Batch 99] Time: 0.01s | CPU: 24.8% | RAM: 133.22GB | GPU: 44.09MB\n",
      "[Batch 100] Time: 0.01s | CPU: 5.2% | RAM: 132.13GB | GPU: 44.09MB\n",
      "[Batch 101] Time: 0.01s | CPU: 5.7% | RAM: 132.01GB | GPU: 44.09MB\n",
      "[Batch 102] Time: 0.01s | CPU: 5.3% | RAM: 131.90GB | GPU: 44.09MB\n",
      "[Batch 103] Time: 0.01s | CPU: 5.5% | RAM: 131.77GB | GPU: 44.09MB\n",
      "[Batch 104] Time: 0.01s | CPU: 19.6% | RAM: 131.83GB | GPU: 44.09MB\n",
      "[Batch 105] Time: 0.01s | CPU: 20.2% | RAM: 132.31GB | GPU: 44.09MB\n",
      "[Batch 106] Time: 0.01s | CPU: 5.4% | RAM: 132.31GB | GPU: 44.09MB\n",
      "[Batch 107] Time: 0.01s | CPU: 6.2% | RAM: 132.31GB | GPU: 44.09MB\n",
      "[Batch 108] Time: 0.01s | CPU: 23.8% | RAM: 132.95GB | GPU: 44.09MB\n",
      "[Batch 109] Time: 0.01s | CPU: 4.7% | RAM: 132.95GB | GPU: 44.09MB\n",
      "[Batch 110] Time: 0.01s | CPU: 9.1% | RAM: 132.98GB | GPU: 44.09MB\n",
      "[Batch 111] Time: 0.01s | CPU: 55.9% | RAM: 133.37GB | GPU: 44.09MB\n",
      "[Batch 112] Time: 0.02s | CPU: 9.1% | RAM: 133.49GB | GPU: 44.09MB\n",
      "[Batch 113] Time: 0.01s | CPU: 28.9% | RAM: 133.80GB | GPU: 44.09MB\n",
      "[Batch 114] Time: 0.01s | CPU: 6.1% | RAM: 133.80GB | GPU: 44.09MB\n",
      "[Batch 115] Time: 0.01s | CPU: 6.1% | RAM: 133.80GB | GPU: 44.09MB\n",
      "[Batch 116] Time: 0.02s | CPU: 10.8% | RAM: 133.30GB | GPU: 44.09MB\n",
      "[Batch 117] Time: 0.01s | CPU: 31.2% | RAM: 133.80GB | GPU: 44.09MB\n",
      "[Batch 118] Time: 0.01s | CPU: 35.2% | RAM: 134.15GB | GPU: 44.09MB\n",
      "[Batch 119] Time: 0.01s | CPU: 48.8% | RAM: 134.55GB | GPU: 44.09MB\n",
      "[Batch 120] Time: 0.02s | CPU: 12.3% | RAM: 134.93GB | GPU: 44.09MB\n",
      "[Batch 121] Time: 0.01s | CPU: 18.3% | RAM: 135.19GB | GPU: 44.09MB\n",
      "[Batch 122] Time: 0.01s | CPU: 4.7% | RAM: 135.20GB | GPU: 44.09MB\n",
      "[Batch 123] Time: 0.01s | CPU: 6.2% | RAM: 135.20GB | GPU: 44.09MB\n",
      "[Batch 124] Time: 0.01s | CPU: 15.6% | RAM: 135.81GB | GPU: 44.09MB\n",
      "[Batch 125] Time: 0.01s | CPU: 4.4% | RAM: 135.82GB | GPU: 44.09MB\n",
      "[Batch 126] Time: 0.01s | CPU: 51.0% | RAM: 136.19GB | GPU: 44.09MB\n",
      "[Batch 127] Time: 0.01s | CPU: 33.0% | RAM: 136.35GB | GPU: 44.09MB\n",
      "[Batch 128] Time: 0.01s | CPU: 15.5% | RAM: 136.92GB | GPU: 44.09MB\n",
      "[Batch 129] Time: 0.01s | CPU: 10.0% | RAM: 136.97GB | GPU: 44.09MB\n",
      "[Batch 130] Time: 0.01s | CPU: 5.3% | RAM: 136.98GB | GPU: 44.09MB\n",
      "[Batch 131] Time: 0.01s | CPU: 5.7% | RAM: 136.97GB | GPU: 44.09MB\n",
      "[Batch 132] Time: 0.01s | CPU: 17.4% | RAM: 137.45GB | GPU: 44.09MB\n",
      "[Batch 133] Time: 0.01s | CPU: 5.2% | RAM: 137.02GB | GPU: 44.09MB\n",
      "[Batch 134] Time: 0.01s | CPU: 5.4% | RAM: 136.89GB | GPU: 44.09MB\n",
      "[Batch 135] Time: 0.01s | CPU: 5.6% | RAM: 136.73GB | GPU: 44.09MB\n",
      "[Batch 136] Time: 0.01s | CPU: 5.9% | RAM: 136.40GB | GPU: 44.09MB\n",
      "[Batch 137] Time: 0.01s | CPU: 5.2% | RAM: 135.15GB | GPU: 44.09MB\n",
      "[Batch 138] Time: 0.01s | CPU: 5.4% | RAM: 134.98GB | GPU: 44.09MB\n",
      "[Batch 139] Time: 0.01s | CPU: 6.4% | RAM: 134.82GB | GPU: 44.09MB\n",
      "[Batch 140] Time: 0.01s | CPU: 5.7% | RAM: 134.41GB | GPU: 44.09MB\n",
      "[Batch 141] Time: 0.01s | CPU: 5.4% | RAM: 133.53GB | GPU: 44.09MB\n",
      "[Batch 142] Time: 0.01s | CPU: 6.6% | RAM: 133.46GB | GPU: 44.09MB\n",
      "[Batch 143] Time: 0.01s | CPU: 3.8% | RAM: 133.46GB | GPU: 44.09MB\n",
      "[Batch 144] Time: 0.01s | CPU: 5.3% | RAM: 133.47GB | GPU: 44.09MB\n",
      "[Batch 145] Time: 0.01s | CPU: 5.6% | RAM: 133.46GB | GPU: 44.09MB\n",
      "[Batch 146] Time: 0.01s | CPU: 5.9% | RAM: 133.46GB | GPU: 44.09MB\n",
      "[Batch 147] Time: 0.01s | CPU: 5.9% | RAM: 133.46GB | GPU: 44.09MB\n",
      "[Batch 148] Time: 0.01s | CPU: 10.1% | RAM: 133.58GB | GPU: 44.09MB\n",
      "[Batch 149] Time: 0.01s | CPU: 5.9% | RAM: 133.61GB | GPU: 44.09MB\n",
      "[Batch 150] Time: 0.01s | CPU: 5.9% | RAM: 133.61GB | GPU: 44.09MB\n",
      "[Batch 151] Time: 0.01s | CPU: 7.8% | RAM: 133.62GB | GPU: 44.09MB\n",
      "[Batch 152] Time: 0.01s | CPU: 5.8% | RAM: 133.63GB | GPU: 44.09MB\n",
      "[Batch 153] Time: 0.01s | CPU: 5.6% | RAM: 133.68GB | GPU: 44.09MB\n",
      "[Batch 154] Time: 0.01s | CPU: 5.5% | RAM: 133.69GB | GPU: 44.09MB\n",
      "[Batch 155] Time: 0.01s | CPU: 6.1% | RAM: 133.68GB | GPU: 44.09MB\n",
      "[Batch 156] Time: 0.01s | CPU: 6.9% | RAM: 133.69GB | GPU: 44.09MB\n",
      "[Batch 157] Time: 0.01s | CPU: 6.3% | RAM: 133.75GB | GPU: 44.09MB\n",
      "[Batch 158] Time: 0.01s | CPU: 7.3% | RAM: 133.76GB | GPU: 44.09MB\n",
      "[Batch 159] Time: 0.01s | CPU: 7.7% | RAM: 133.77GB | GPU: 44.09MB\n",
      "[Batch 160] Time: 0.01s | CPU: 7.4% | RAM: 133.79GB | GPU: 44.09MB\n",
      "[Batch 161] Time: 0.01s | CPU: 7.1% | RAM: 133.82GB | GPU: 44.09MB\n",
      "[Batch 162] Time: 0.01s | CPU: 8.3% | RAM: 133.82GB | GPU: 44.09MB\n",
      "[Batch 163] Time: 0.01s | CPU: 7.5% | RAM: 133.82GB | GPU: 44.09MB\n",
      "[Batch 164] Time: 0.01s | CPU: 6.0% | RAM: 133.84GB | GPU: 44.09MB\n",
      "[Batch 165] Time: 0.02s | CPU: 9.2% | RAM: 133.92GB | GPU: 44.09MB\n",
      "[Batch 166] Time: 0.01s | CPU: 8.9% | RAM: 133.93GB | GPU: 44.09MB\n",
      "[Batch 167] Time: 0.01s | CPU: 9.4% | RAM: 133.94GB | GPU: 44.09MB\n",
      "[Batch 168] Time: 0.01s | CPU: 9.4% | RAM: 133.94GB | GPU: 44.09MB\n",
      "[Batch 169] Time: 0.01s | CPU: 9.7% | RAM: 134.03GB | GPU: 44.09MB\n",
      "[Batch 170] Time: 0.01s | CPU: 11.1% | RAM: 133.76GB | GPU: 44.09MB\n",
      "[Batch 171] Time: 0.01s | CPU: 11.6% | RAM: 133.17GB | GPU: 44.09MB\n",
      "[Batch 172] Time: 0.01s | CPU: 13.0% | RAM: 132.79GB | GPU: 44.09MB\n",
      "[Batch 173] Time: 0.01s | CPU: 14.4% | RAM: 132.59GB | GPU: 44.09MB\n",
      "[Batch 174] Time: 0.01s | CPU: 12.8% | RAM: 132.63GB | GPU: 44.09MB\n",
      "[Batch 175] Time: 0.01s | CPU: 9.3% | RAM: 132.65GB | GPU: 44.09MB\n",
      "[Batch 176] Time: 0.01s | CPU: 8.9% | RAM: 132.67GB | GPU: 44.09MB\n",
      "[Batch 177] Time: 0.01s | CPU: 10.7% | RAM: 132.81GB | GPU: 44.09MB\n",
      "[Batch 178] Time: 0.01s | CPU: 10.7% | RAM: 132.82GB | GPU: 44.09MB\n",
      "[Batch 179] Time: 0.01s | CPU: 11.0% | RAM: 132.82GB | GPU: 44.09MB\n",
      "[Batch 180] Time: 0.01s | CPU: 11.3% | RAM: 132.82GB | GPU: 44.09MB\n",
      "[Batch 181] Time: 0.01s | CPU: 9.3% | RAM: 132.86GB | GPU: 44.09MB\n",
      "[Batch 182] Time: 0.01s | CPU: 9.8% | RAM: 132.87GB | GPU: 44.09MB\n",
      "[Batch 183] Time: 0.01s | CPU: 11.2% | RAM: 132.87GB | GPU: 44.09MB\n",
      "[Batch 184] Time: 0.01s | CPU: 9.6% | RAM: 132.87GB | GPU: 44.09MB\n",
      "[Batch 185] Time: 0.01s | CPU: 9.1% | RAM: 132.89GB | GPU: 44.09MB\n",
      "[Batch 186] Time: 0.01s | CPU: 11.2% | RAM: 132.90GB | GPU: 44.09MB\n",
      "[Batch 187] Time: 0.01s | CPU: 9.3% | RAM: 132.90GB | GPU: 44.09MB\n",
      "[Batch 188] Time: 0.01s | CPU: 8.7% | RAM: 132.91GB | GPU: 44.09MB\n",
      "[Batch 189] Time: 0.01s | CPU: 8.0% | RAM: 132.91GB | GPU: 44.09MB\n",
      "[Batch 190] Time: 0.01s | CPU: 8.2% | RAM: 132.92GB | GPU: 44.09MB\n",
      "[Batch 191] Time: 0.01s | CPU: 8.0% | RAM: 132.91GB | GPU: 44.09MB\n",
      "[Batch 192] Time: 0.01s | CPU: 8.6% | RAM: 132.92GB | GPU: 44.09MB\n",
      "[Batch 193] Time: 0.02s | CPU: 8.2% | RAM: 132.92GB | GPU: 28.58MB\n"
     ]
    }
   ],
   "source": [
    "start_time = time.time()\n",
    "with torch.no_grad():\n",
    "    for i, (inputs, labels) in enumerate(test_loader):\n",
    "        batch_start = time.time()\n",
    "        inputs, labels = inputs.to(device), labels.to(device)\n",
    "\n",
    "        outputs = trained_model(inputs)\n",
    "        preds = torch.argmax(outputs, dim=1)\n",
    "        all_preds.extend(preds.cpu().numpy())\n",
    "        all_labels.extend(labels.cpu().numpy())\n",
    "\n",
    "        # --- Profiling ---\n",
    "        cpu_usage = psutil.cpu_percent(interval=None)\n",
    "        ram = psutil.virtual_memory()\n",
    "        if torch.cuda.is_available():\n",
    "            gpu_mem = torch.cuda.memory_allocated() / 1024**2\n",
    "        else:\n",
    "            gpu_mem = 0.0\n",
    "        print(f\"[Batch {i+1}] Time: {time.time()-batch_start:.2f}s | CPU: {cpu_usage:.1f}% | RAM: {ram.used/1024**3:.2f}GB | GPU: {gpu_mem:.2f}MB\")\n",
    "\n",
    "end_time = time.time()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Temps Test Total: 8.44 sec\n",
      "Throughput: 728.68 images/sec\n"
     ]
    }
   ],
   "source": [
    "total_time = end_time - start_time\n",
    "print(f\"\\nTemps Test Total: {total_time:.2f} sec\")\n",
    "print(f\"Throughput: {len(test_dataset) / total_time:.2f} images/sec\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Rapport complet d'évaluation sur l'ensemble de test (VGG11) ===\n",
      "                                               precision    recall  f1-score   support\n",
      "\n",
      "                           Apple___Apple_scab       0.96      0.81      0.88       100\n",
      "                            Apple___Black_rot       0.99      0.93      0.96       100\n",
      "                     Apple___Cedar_apple_rust       0.97      0.96      0.96       100\n",
      "                              Apple___healthy       0.89      0.91      0.90       164\n",
      "                    Background_without_leaves       0.96      0.94      0.95       114\n",
      "                          Blueberry___healthy       0.93      0.98      0.95       150\n",
      "                      Cherry___Powdery_mildew       0.97      0.90      0.94       105\n",
      "                             Cherry___healthy       0.96      0.98      0.97       100\n",
      "   Corn___Cercospora_leaf_spot Gray_leaf_spot       0.89      0.88      0.88       100\n",
      "                           Corn___Common_rust       0.97      0.99      0.98       119\n",
      "                  Corn___Northern_Leaf_Blight       0.85      0.89      0.87       100\n",
      "                               Corn___healthy       1.00      0.97      0.99       116\n",
      "                            Grape___Black_rot       0.97      0.86      0.91       118\n",
      "                 Grape___Esca_(Black_Measles)       0.89      0.97      0.93       138\n",
      "   Grape___Leaf_blight_(Isariopsis_Leaf_Spot)       0.99      0.97      0.98       108\n",
      "                              Grape___healthy       0.92      0.98      0.95       100\n",
      "     Orange___Haunglongbing_(Citrus_greening)       0.98      1.00      0.99       551\n",
      "                       Peach___Bacterial_spot       0.87      0.94      0.91       230\n",
      "                              Peach___healthy       0.96      0.92      0.94       100\n",
      "                Pepper,_bell___Bacterial_spot       0.76      0.90      0.83       100\n",
      "                       Pepper,_bell___healthy       0.86      0.95      0.90       148\n",
      "                        Potato___Early_blight       0.98      0.88      0.93       100\n",
      "                         Potato___Late_blight       0.89      0.83      0.86       100\n",
      "                             Potato___healthy       0.99      0.81      0.89       100\n",
      "                          Raspberry___healthy       0.93      0.96      0.95       100\n",
      "                            Soybean___healthy       0.93      0.98      0.96       509\n",
      "                      Squash___Powdery_mildew       0.96      0.99      0.97       184\n",
      "                     Strawberry___Leaf_scorch       0.94      0.95      0.95       111\n",
      "                         Strawberry___healthy       0.97      0.95      0.96       100\n",
      "                      Tomato___Bacterial_spot       0.91      0.82      0.86       213\n",
      "                        Tomato___Early_blight       0.69      0.68      0.69       100\n",
      "                         Tomato___Late_blight       0.85      0.79      0.82       191\n",
      "                           Tomato___Leaf_Mold       0.86      0.79      0.82       100\n",
      "                  Tomato___Septoria_leaf_spot       0.85      0.83      0.84       177\n",
      "Tomato___Spider_mites Two-spotted_spider_mite       0.84      0.88      0.85       168\n",
      "                         Tomato___Target_Spot       0.72      0.75      0.73       140\n",
      "       Tomato___Tomato_Yellow_Leaf_Curl_Virus       0.99      0.96      0.97       536\n",
      "                 Tomato___Tomato_mosaic_virus       0.97      0.94      0.95       100\n",
      "                             Tomato___healthy       0.90      0.96      0.93       159\n",
      "\n",
      "                                     accuracy                           0.92      6149\n",
      "                                    macro avg       0.92      0.91      0.91      6149\n",
      "                                 weighted avg       0.92      0.92      0.92      6149\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Rapport complet\n",
    "print(\"=== Rapport complet d'évaluation sur l'ensemble de test (VGG11) ===\")\n",
    "print(classification_report(all_labels, all_preds, target_names=class_names))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "gpu",
   "dataSources": [],
   "dockerImageVersionId": 31040,
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
